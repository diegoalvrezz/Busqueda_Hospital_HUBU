{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xjuYV7XrEmt"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "import unidecode\n",
        "\n",
        "########################\n",
        "# Funciones auxiliares #\n",
        "########################\n",
        "\n",
        "def remove_accents(text: str) -> str:\n",
        "    \"\"\"Elimina acentos/tildes, para facilitar b√∫squedas insensibles a acentos.\"\"\"\n",
        "    return unidecode.unidecode(text)\n",
        "\n",
        "\n",
        "def contiene_frase(base_text: str, frase: str) -> bool:\n",
        "    \"\"\"Verifica si `frase` (sin acentos y case-insensitive) est√° en `base_text`.\"\"\"\n",
        "    base_limpio = remove_accents(base_text.lower())\n",
        "    frase_limpio = remove_accents(frase.lower())\n",
        "    return frase_limpio in base_limpio\n",
        "\n",
        "\n",
        "def extrae_patron(text: str, patron: str) -> str:\n",
        "    \"\"\"Devuelve la primera coincidencia (grupo 1) de `patron` en `text`, o None si no hay match.\"\"\"\n",
        "    match = re.search(patron, text, flags=re.IGNORECASE)\n",
        "    if match and match.group(1).strip():\n",
        "        return match.group(1).strip()\n",
        "    return None\n",
        "\n",
        "######################################\n",
        "# Funci√≥n principal de parseo INFORME #\n",
        "######################################\n",
        "\n",
        "def parse_informe(texto_informe: str) -> dict:\n",
        "    \"\"\"Parsea un bloque de texto que corresponde a un informe (un paciente)\n",
        "    y devuelve un diccionario con los valores encontrados, o None si no cumple.\"\"\"\n",
        "\n",
        "    texto_informe = \" \".join(texto_informe.split(\"\\n\"))  # Une l√≠neas separadas\n",
        "\n",
        "    # Extraer los datos con regex flexibles\n",
        "    patron_nhc = r\"(?i)n\\s*h\\s*c\\s*[:\\-]?\\s*(\\d{6})\"\n",
        "    patron_biopsia = r\"(?i)n¬∫\\s*de\\s*muestra\\s*/?\\s*biopsia\\s*[:\\-]?\\s*(.+)\"\n",
        "    patron_procedencia = r\"(?i)-\\s*procedencia\\s*anat[√≥o]mica\\s*[:\\-]?\\s*([^\\n]+)\"\n",
        "    patron_diagnostico = r\"(?i)diagn[√≥o]stico\\s*[:\\-]?\\s*([^\\n]+)\"\n",
        "\n",
        "    nhc = extrae_patron(texto_informe, patron_nhc)\n",
        "    biopsia = extrae_patron(texto_informe, patron_biopsia)\n",
        "    procedencia_raw = extrae_patron(texto_informe, patron_procedencia)\n",
        "    diagnostico = extrae_patron(texto_informe, patron_diagnostico)\n",
        "    resultado_hallado = contiene_frase(texto_informe, \"NO SE DETECTA p√©rdida\")\n",
        "\n",
        "    # Validar que procedencia contiene exclusivamente una de las palabras clave\n",
        "    procedencia_valida = None\n",
        "    if procedencia_raw:\n",
        "        p_limpio = remove_accents(procedencia_raw.lower())\n",
        "        palabras_validas = [\"colon\", \"sigma\", \"recto\", \"intestino grueso\"]\n",
        "        if any(p_limpio.startswith(palabra) for palabra in palabras_validas):\n",
        "            procedencia_valida = procedencia_raw.strip()\n",
        "        else:\n",
        "            return None  # Si no cumple, se descarta el informe\n",
        "\n",
        "    # üîç DEBUG: Mostrar qu√© datos se est√°n encontrando\n",
        "    print(\"\\n--- DEBUG: Informaci√≥n extra√≠da ---\")\n",
        "    print(f\"NHC detectado: {nhc}\")\n",
        "    print(f\"Biopsia detectada: {biopsia}\")\n",
        "    print(f\"Procedencia detectada: {procedencia_valida}\")\n",
        "    print(f\"Diagn√≥stico detectado: {diagnostico}\")\n",
        "    print(f\"Resultado detectado: {'S√≠' if resultado_hallado else 'No'}\")\n",
        "    print(\"-----------------------------------\\n\")\n",
        "\n",
        "    # Validaci√≥n final: si falta alg√∫n dato, se descarta el informe\n",
        "    if nhc and biopsia and procedencia_valida and diagnostico and resultado_hallado:\n",
        "        return {\n",
        "            \"NHC\": nhc,\n",
        "            \"Muestra/Biopsia\": biopsia.strip(),\n",
        "            \"Procedencia\": procedencia_valida,\n",
        "            \"Diagnostico\": diagnostico.strip(),\n",
        "            \"Resultado\": \"NO SE DETECTA p√©rdida\"\n",
        "        }\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "############################################\n",
        "# Funci√≥n para procesar el PDF completo    #\n",
        "############################################\n",
        "\n",
        "def extraer_informes_pdf(pdf_path: str):\n",
        "    \"\"\"Lee todo el PDF y separa los informes en base a la aparici√≥n de 'N¬∫ de muestra/biopsia'.\"\"\"\n",
        "\n",
        "    doc = fitz.open(pdf_path)\n",
        "    lineas = [(pagenum + 1, t) for pagenum in range(len(doc)) for t in doc[pagenum].get_text(\"text\").split(\"\\n\")]\n",
        "    resultados = []\n",
        "\n",
        "    i = 0\n",
        "    while i < len(lineas):\n",
        "        pageno, text_line = lineas[i]\n",
        "\n",
        "        # üîç Buscar \"N¬∫ de muestra/biopsia:\" en lugar de NHC\n",
        "        if re.search(r\"(?i)n¬∫\\s*de\\s*muestra\\s*/?\\s*biopsia\", text_line):\n",
        "            bloque_inicio = i\n",
        "            j = i + 1\n",
        "            while j < len(lineas) and not re.search(r\"(?i)n¬∫\\s*de\\s*muestra\\s*/?\\s*biopsia\", lineas[j][1]):\n",
        "                j += 1\n",
        "            chunk_text = \"\\n\".join([l[1] for l in lineas[bloque_inicio:j]])\n",
        "            informe_data = parse_informe(chunk_text)\n",
        "            if informe_data:\n",
        "                informe_data[\"Pagina\"] = pageno\n",
        "                resultados.append(informe_data)\n",
        "            i = j\n",
        "        else:\n",
        "            i += 1\n",
        "    return resultados\n",
        "\n",
        "############################################\n",
        "# Funci√≥n para guardar resultados en Excel #\n",
        "############################################\n",
        "\n",
        "def guardar_en_excel(datos, output_path: str):\n",
        "    df = pd.DataFrame(datos)\n",
        "    df.to_excel(output_path, index=False)\n",
        "    print(f\"Resultados guardados en {output_path}\")\n",
        "\n",
        "############################################\n",
        "# Funci√≥n para combinar datos de Excel     #\n",
        "############################################\n",
        "\n",
        "def combinar_resultados(base_resultados: str, base_biobancbdd: str, output_final: str):\n",
        "    \"\"\"Combina los datos de resultados.xlsx con biobancbdd.xlsx mediante un JOIN en 'NHC' usando √≠ndices de columna.\"\"\"\n",
        "\n",
        "    # Cargar los archivos\n",
        "    df_resultados = pd.read_excel(base_resultados)\n",
        "    df_biobanc = pd.read_excel(base_biobancbdd)\n",
        "\n",
        "    # üîç DEBUG: Mostrar nombres de columnas en biobancbdd.xlsx\n",
        "    print(\"\\nüìå Columnas en 'biobancbdd.xlsx':\")\n",
        "    print(df_biobanc.columns.tolist())\n",
        "\n",
        "    # Seleccionar columnas usando √≠ndices\n",
        "    try:\n",
        "        df_biobanc = df_biobanc.iloc[:, [0, 1, 2, 3, 4, 5, 6, 7, 8]]  # Ajusta seg√∫n el orden real en el archivo\n",
        "        df_biobanc.columns = [\"HC\", \"Fecha de obtenci√≥n\", \"Caja\", \"Posici√≥n\", \"NHC\",\n",
        "                              \"Codificador Morfol√≥gico 1\", \"Codificador Topogr√°fico 1\",\n",
        "                              \"Consentimiento\", \"√ìrgano\"]\n",
        "    except IndexError:\n",
        "        print(\"‚ùå ERROR: El archivo 'biobancbdd.xlsx' no tiene suficientes columnas.\")\n",
        "        return\n",
        "\n",
        "    # Realizar la combinaci√≥n por NHC\n",
        "    df_final = pd.merge(df_resultados, df_biobanc, on=\"NHC\", how=\"left\")\n",
        "\n",
        "    # Guardar el nuevo Excel\n",
        "    df_final.to_excel(output_final, index=False)\n",
        "    print(f\"‚úÖ Archivo combinado guardado en {output_final}\")\n",
        "\n",
        "\n",
        "###########################################\n",
        "# Ejemplo de uso                          #\n",
        "###########################################\n",
        "if __name__ == \"__main__\":\n",
        "    pdf_path = \"archivo.pdf\"  # Cambiar por la ruta real\n",
        "    output_excel = \"resultados.xlsx\"\n",
        "    output_final_excel = \"resultadosfinal.xlsx\"\n",
        "    base_biobancbdd = \"biobancbdd.xlsx\"  # Archivo externo\n",
        "\n",
        "    # Extraer informes desde el PDF\n",
        "    resultados = extraer_informes_pdf(pdf_path)\n",
        "    if resultados:\n",
        "        guardar_en_excel(resultados, output_excel)\n",
        "        # Combinar con la base de datos externa\n",
        "        combinar_resultados(output_excel, base_biobancbdd, output_final_excel)\n",
        "    else:\n",
        "        print(\"No se encontraron informes que cumplan todos los criterios.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def merge_and_save_results(resultados_path, biobancbdd_path, output_path):\n",
        "    # Cargar las bases de datos\n",
        "    df_resultados = pd.read_excel(resultados_path)\n",
        "    df_biobancbdd = pd.read_excel(biobancbdd_path)\n",
        "\n",
        "    # Seleccionar las columnas deseadas de biobancbdd\n",
        "    columns_to_keep = [\"HC\", \"Fecha de obtenci√≥n\", \"Caja\", \"Posici√≥n\", \"NHC\",\n",
        "                       \"Codificador Morfol√≥gico 1\", \"Codificador Topogr√°fico 1\",\n",
        "                       \"Consentimiento\", \"√ìrgano\"]\n",
        "    df_biobancbdd = df_biobancbdd[columns_to_keep]\n",
        "\n",
        "    # Realizar la uni√≥n de ambas bases de datos por el campo NHC\n",
        "    df_merged = pd.merge(df_resultados, df_biobancbdd, on=\"NHC\", how=\"left\")\n",
        "\n",
        "    # Guardar el resultado en un nuevo archivo Excel\n",
        "    df_merged.to_excel(output_path, index=False)\n",
        "\n",
        "    print(f\"Archivo guardado exitosamente en {output_path}\")\n",
        "\n",
        "# Ejemplo de uso\n",
        "merge_and_save_results(\"resultados.xlsx\", \"biobancbdd.xlsx\", \"RESULTADOS_FINALES.xlsx\")\n"
      ],
      "metadata": {
        "id": "t_R6let_SOIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- DEBUG: Informaci√≥n extra√≠da ---\n",
        "NHC detectado: 124168\n",
        "Biopsia detectada: 22B-14462             -Procedencia anat√≥mica: intestino grueso.   -Diagn√≥stico: adenoc"
      ],
      "metadata": {
        "id": "QbETp_9t6UrT"
      }
    }
  ]
}